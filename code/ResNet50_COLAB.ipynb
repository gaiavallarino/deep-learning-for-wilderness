{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOFJjFIg4h2yevEPst9hnBq"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# RESNET-50\n","### Experiment of implementation"],"metadata":{"id":"jjQMZ6QM6M7-"}},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0KKvOPtV6LFq","executionInfo":{"status":"ok","timestamp":1701963096967,"user_tz":-60,"elapsed":24684,"user":{"displayName":"Gaia Vallarino","userId":"17839777930176726024"}},"outputId":"afd84e3d-26ca-4853-a48c-c78fef0d8c2d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["# Mount the Google Drive\n","from google.colab import drive\n","drive.mount(\"/content/drive\")"]},{"cell_type":"code","source":["#%% LIBRARIES #################################################################\n","import os\n","import random\n","import time\n","import numpy as np\n","from osgeo import gdal\n","import pandas as pd\n","from google.colab import drive\n","from PIL import Image\n","import tifffile as tiff\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torchvision import models, transforms\n","from torch.nn.functional import relu\n","from torchvision.models import resnet50\n","from torch.utils.data import Dataset, DataLoader\n","import matplotlib.pyplot as plt\n","from datetime import datetime\n","\n","#%% SEED ######################################################################\n","seed = 1\n","torch.manual_seed(seed)\n","random.seed(seed)\n","np.random.seed(seed)\n","\n","#%% RESNET50 MODEL CLASS #################################################################\n","class ResNet50(nn.Module):\n","    def __init__(self, num_classes, band, pt_value):\n","        super(ResNet50, self).__init__()\n","\n","        resnet = resnet50(pretrained = pt_value)  # Use pre-trained ResNet50\n","\n","        # Modify the first convolutional layer to accept variable input channels\n","        if band != 3:\n","\n","            # Adjust the first convolutional layer to accept the new number of input channels\n","            resnet.conv1 = nn.Conv2d(band, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","\n","        # Remove the fully connected layers (classification head) of ResNet50\n","        self.features = nn.Sequential(*list(resnet.children())[:-2])\n","\n","        # Additional layers for adapting to your specific task\n","        self.pool = nn.AdaptiveAvgPool2d(1)\n","        self.fc1 = nn.Linear(2048, 128)\n","        self.fc2 = nn.Linear(128, num_classes)\n","\n","    def forward(self, x):\n","        x = self.features(x)\n","        x = self.pool(x)\n","        x = x.view(x.size(0), -1)\n","        x = relu(self.fc1(x))\n","        x = self.fc2(x)\n","        print(\"Forward done\")\n","        return x\n","\n","#%% DATASET CLASS ##############################################################\n","class CustomDataset(Dataset):\n","  def __init__(self, csv_file, Data_Folder, transform = None, datasplit = None, bands = None):\n","    self.data = pd.read_csv(csv_file, sep = \";\", skiprows=None)\n","    if datasplit:\n","      self.data = self.data[self.data[\"datasplit\"] == datasplit]\n","    self.data = self.data.reset_index(drop=True, inplace=False)\n","    self.image_paths = self.data['file']\n","    self.image_folder = Data_Folder\n","    self.target_values = self.data['label']\n","    self.transform = transform\n","    self.bands = bands\n","  def __len__(self):\n","    return len(self.image_paths)\n","  def __getitem__(self, idx):\n","    #print(\"Accessing item at index:\", idx)\n","    #construct image path by joining folder path and image name\n","    image_name = self.image_paths[idx]\n","    image_path = os.path.join(self.image_folder, image_name)\n","    #open image using PIL\n","    #image = tiff.imread(image_path)\n","    image = tiff.imread(image_path)[:, :, self.bands]\n","    #print(\"Original image shape:\", image.shape)\n","    image = np.squeeze(image, axis=2)\n","    image = Image.fromarray((image * 255).astype('uint8'))\n","    #print(\"Converted image shape:\", image.size)\n","    if self.transform:\n","      image = self.transform(image)\n","    #Mohamed's normalization method\n","    image= image[:,:,:]/10000\n","\n","    #image = image.astype('float32')\n","    #image = torch.from_numpy(image)\n","\n","    #get the labels\n","    label = int(self.target_values[idx])\n","    #print('Labels 1:', label)\n","    label = np.array(label).astype('float32')\n","    #print('Labels 2:', label)\n","    label = torch.tensor(label, dtype=torch.long)  # Convert label to a tensor\n","    #print('Labels 3:', label)\n","    return image, label\n","\n","# Set file directory of the location where the data is stored\n","Data_Folder = \"/content/drive/MyDrive/Master's Thesis/DATA/dataset_10bands_inc\"\n","csv_file = \"/content/drive/MyDrive/Master's Thesis/DATA/new_dataset_s2.csv\"\n","log_file_path = \"/content/drive/MyDrive/Master's Thesis/DATA/results/experiment_log.txt\"\n","\n","# Set transformation\n","transform = transforms.Compose([\n","    transforms.Resize((224, 224)),\n","    transforms.ToTensor(),\n","])\n","\n","# Set bands for experiments\n","bands = [[0]]\n","\n","for band in bands:\n","    print(band)\n","\n","    #%% INITIATE DATASETS ###################################################################\n","    train_dataset = CustomDataset(csv_file, Data_Folder, transform=transform, datasplit=\"train\", bands=band)\n","    test_dataset = CustomDataset(csv_file, Data_Folder, transform=transform, datasplit=\"test\", bands=band)\n","    validation_dataset = CustomDataset(csv_file, Data_Folder, transform=transform, datasplit=\"val\", bands=band)\n","\n","    #%% CREATE MODEL & LOSS & OPTIMIZER ###################################################################\n","    # Set seed for Model Initialization\n","    torch.manual_seed(seed)\n","    # Create the instance of our Network\n","    model = ResNet50(4, len(band), True) # True = pre-trained; False = from scratch\n","    # Define loss function (e.g., Cross-Entropy Loss for segmentation)\n","    loss_fn = nn.CrossEntropyLoss()\n","    # Define optimizer (e.g., Adam optimizer)\n","    optimizer = optim.Adam(model.parameters(), lr=0.001)\n","\n","    #%% SETTING SEED, BATCH_SIZE, DATALOADER ###################################################################\n","    # Set seed for DataLoader (if using shuffle)\n","    torch.manual_seed(seed)\n","    # Data Loader Creation\n","    batch_size = 64\n","    # Current Version: only load \"train\" in the data loader\n","    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","    val_loader = DataLoader(validation_dataset, batch_size=batch_size, shuffle=False)\n","    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n","\n","    #%% TRAINING LOOP ###################################################################\n","\n","    # Empty list to store loss values for visualization\n","    train_loss_values = []\n","    val_loss_values = []\n","    test_loss_values = []\n","\n","    # Create a text file to save the parameters and loss\n","    log_file = open(log_file_path, \"a\")  # \"a\" mode appends to the file\n","    log_file.write(f\"********************************************************\\n\")\n","    current_datetime = datetime.now()\n","    log_file.write(f\"EXPERIMENT OF: {current_datetime}\\n\")\n","    log_file.write(f\"############\\nNOTES:\\nBAND(S) CONSIDERED: {band}\\nSEED: {seed}\\nLEARNINGRATE: lr\\n\")\n","    log_file.write(f\"TRAINING\\n\")\n","    log_file.write(f\"\\n\")\n","\n","\n","    #%% TRAINING ###################################################################\n","    torch.manual_seed(seed)\n","    num_epochs = 1\n","    for epoch in range(num_epochs):\n","        print(\"Epoch:\", epoch+1)\n","        start_time = time.time()\n","        ############################# TRAINING STEP\n","        model.train()  # Set the model to training mode\n","        total_loss = 0\n","        for batch in train_loader:\n","            inputs, targets = batch\n","            #inputs = inputs.permute(0, 3, 1, 2)\n","            # Forward pass\n","            outputs = model(inputs)\n","            # Compute loss\n","            loss = loss_fn(outputs, targets)\n","            total_loss += loss.item()\n","            # Backward pass and optimization\n","            optimizer.zero_grad()\n","            loss.backward()\n","            optimizer.step()\n","            print(\"current batch completed\")\n","            current_time = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n","            print(\"Current Time:\", current_time)\n","        # Calculate the average loss for the epoch\n","        avg_loss = total_loss / len(train_loader)\n","        # Append the loss to the list\n","        train_loss_values.append(avg_loss)\n","        # Print average loss for the epoch\n","        print(f\"Epoch [{epoch + 1}/{num_epochs}], Training Loss: {avg_loss}\\n\")\n","        # Save parameters and loss to the log file\n","        log_file.write(f\"Epoch [{epoch + 1}/{num_epochs}], Training Loss: {avg_loss}\\n\")\n","        print(\"**********************************\")\n","        print(\"training done\")\n","        ############### VALIDATION STEP\n","        # Create a text file to save the parameters and loss\n","        log_file.write(f\"-----------\\n\")\n","        log_file.write(f\"EVALUATION\\n\")\n","        # Set seed for validation loop\n","        torch.manual_seed(seed)\n","        model.eval()  # Set the model to evaluation mode\n","        total_val_loss = 0\n","        with torch.no_grad():  # Disable gradient calculation for validation\n","            for val_batch in val_loader:\n","                val_inputs, val_targets = val_batch\n","                #val_inputs = val_inputs.permute(0, 3, 1, 2)\n","                # Forward pass for validation\n","                val_outputs = model(val_inputs)\n","                # Compute validation loss\n","                val_loss = loss_fn(val_outputs, val_targets)\n","                total_val_loss += val_loss.item()\n","        # Calculate and print average validation loss and accuracy\n","        avg_val_loss = total_val_loss / len(val_loader)\n","        val_loss_values.append(avg_val_loss)\n","        print(f\"Epoch [{epoch + 1}/{num_epochs}], Validation Loss: {avg_val_loss}\\n\")\n","        # Print value in file\n","        log_file.write(f\"Epoch [{epoch + 1}/{num_epochs}], Validation Loss: {avg_val_loss}\\n\")\n","        end_time = time.time()\n","        elapsed_time = end_time - start_time  # Calculate the elapsed time\n","        print(f\"Time elapsed for epoch {epoch + 1}: {elapsed_time:.2f} seconds, or {elapsed_time/60:.2f} minutes\")\n","    # Close the log file\n","    log_file.close()\n","\n","\n","\n","    #%% TESTING ###################################################################\n","\n","    # Create a text file to save the parameters and loss\n","    log_file_path = \"/content/drive/MyDrive/Master's Thesis/DATA/results/experiment_log.txt\"\n","    log_file = open(log_file_path, \"a\")  # \"a\" mode appends to the file\n","    log_file.write(f\"__________________\\n\")\n","    log_file.write(f\"TESTING\\n\")\n","    # Set seed for testing loop\n","    torch.manual_seed(seed)\n","    model.eval()  # Set the model to evaluation mode\n","    loss_values_test = 0.0\n","    correct = 0\n","    with torch.no_grad():  # Disable gradient calculation for validation\n","        for images, labels in test_loader:\n","            #images = images.permute(0, 3, 1, 2)\n","            # Forward pass\n","            outputs = model(images)\n","            # Calculate validation loss\n","            loss = loss_fn(outputs, labels)\n","            loss_values_test += loss.item()\n","            # Calculate the number of correct predictions\n","            _, predicted = outputs.max(1)\n","            correct += (predicted == labels).sum().item()\n","    # Calculate and print average validation loss and accuracy\n","    avg_test_loss = loss_values_test / len(test_loader.dataset)\n","    accuracy = correct / len(test_loader.dataset) * 100\n","    print(f'Testing Loss: {avg_test_loss:.4f}, Testing Accuracy: {accuracy:.2f}%')\n","    # Print value in the file\n","    log_file.write(f\"Loss: {avg_test_loss}, Accuracy: {accuracy:.2f}\\n\")\n","    # Close the log file\n","    log_file.close()\n","\n","    # PLOT #####################################################\n","    plt.figure()\n","    plt.plot(range(1, num_epochs + 1), train_loss_values, marker='o', linestyle='-', color='blue', label='Training Loss')\n","    plt.plot(range(1, num_epochs + 1), val_loss_values, marker='o', linestyle='-', color='red', label='Validation Loss')\n","    #plt.scatter(num_epochs + 1, avg_test_loss, color='green', label='Testing Loss')\n","    plt.title('Training Loss vs Validation Loss')\n","    plt.xlabel('Epoch')\n","    plt.ylabel('Loss')\n","    plt.legend()\n","    plt.grid(True)\n","    plt.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":513},"id":"xXPvYJN66n-h","executionInfo":{"status":"error","timestamp":1701966274383,"user_tz":-60,"elapsed":68990,"user":{"displayName":"Gaia Vallarino","userId":"17839777930176726024"}},"outputId":"16d8d5fc-d2f5-4601-9879-8fdaabeaa539"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Forward done\n","current batch completed\n","Current Time: 2023-12-07 16:23:47\n","Epoch [1/1], Training Loss: 0.5108140048881372\n","\n","**********************************\n","training done\n"]},{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-9-0efc8588445a>\u001b[0m in \u001b[0;36m<cell line: 114>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    204\u001b[0m                 \u001b[0mval_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m                 \u001b[0;31m# Forward pass for validation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m                 \u001b[0mval_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m                 \u001b[0;31m# Compute validation loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m                 \u001b[0mval_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_targets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-9-0efc8588445a>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    216\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 460\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    454\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[0;32m--> 456\u001b[0;31m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0m\u001b[1;32m    457\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: Given groups=1, weight of size [64, 1, 7, 7], expected input[64, 224, 1, 224] to have 1 channels, but got 224 channels instead"]}]},{"cell_type":"code","source":[],"metadata":{"id":"WBEg5jSpgMLk"},"execution_count":null,"outputs":[]}]}